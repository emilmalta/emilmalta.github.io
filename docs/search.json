[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Population Dynamics of Nuuk\n\n\n\n\n\nWhy does Nuuk have so many more men than women? Exploring how immigration shapes the population across age, gender and neighborhoods.\n\n\n\n\n\nJan 1, 2025\n\n\nEmil Malta\n\n\n\n\n\n\n\n\n\n\n\n\nWright-Fisher simulations in R\n\n\n\n\n\nHow do random changes shape the genetic makeup of a population? Explore the Wright-Fisher model to understand genetic drift, visualize its effects, and how to implement it in R.\n\n\n\n\n\nJan 10, 2025\n\n\nEmil Malta\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/2025-01-03-Wright-Fisher Simulation in R/wright-fisher.html",
    "href": "blog/2025-01-03-Wright-Fisher Simulation in R/wright-fisher.html",
    "title": "Wright-Fisher simulations in R",
    "section": "",
    "text": "This post is for R users (like me), who are interested in evolutionary biology, population genetics, and simulation studies. I’ll go through a few technical implementations of genetic drift in R, visualise the output, and interpret the results. Along the way, I’ll show a simple shiny app to understand the parameters of the model.\nI hope this helps you build some intuition for Wright-Fisher simulation. Much of what I’m about to show is the mental gymnastics I had to perform to get this concept."
  },
  {
    "objectID": "blog/2025-01-03-Wright-Fisher Simulation in R/wright-fisher.html#the-wright-fisher-model",
    "href": "blog/2025-01-03-Wright-Fisher Simulation in R/wright-fisher.html#the-wright-fisher-model",
    "title": "Wright-Fisher simulations in R",
    "section": "The Wright Fisher model",
    "text": "The Wright Fisher model\nMuch of my time as an undergraduate was spent obsessing over allele frequencies. I was/am specifically interested in how certain copies of genes become prominent in a population, or disappear entirely. While it’s true that much of it can be explained by things like natural selection or de novo mutations, allele frequencies in a population just generally change over time by chance alone.\nThis is a process is called genetic drift, and is especially noticeable in small, isolated populations. You typically notice this in sudden reduction of population size, like a natural disaster, or a migration of a small group.\nA common model used to simulate this is called the Wright-Fisher model, which assumes that:\n\nThe size of the population is constant over time.\nThe generations don’t overlap.\nThe change in allele frequencies is a stochastic process.\n\nAllele frequency of each generation comes from sampling a binomial distribution based on the frequency of previous generation. Repeat this enough times, and the allele will eventually be be fixed or lost (all individuals modeled have the allele, or the allele is lost entirely)."
  },
  {
    "objectID": "blog/2025-01-03-Wright-Fisher Simulation in R/wright-fisher.html#shiny-app-tldr",
    "href": "blog/2025-01-03-Wright-Fisher Simulation in R/wright-fisher.html#shiny-app-tldr",
    "title": "Wright-Fisher simulations in R",
    "section": "Shiny app (tl;dr)",
    "text": "Shiny app (tl;dr)\nThis post gets into the weeds of how this stuff is implemented. If your aim is just to understand the model, I’d suggest messing around with this app:\n#| '!! shinylive warning !!': |\n#|   shinylive does not work in self-contained HTML documents.\n#|   Please set `embed-resources: false` in your metadata.\n#| standalone: true\n#| viewerHeight: 840\n\nlibrary(patchwork)\nlibrary(ggplot2)\nlibrary(scales)\nlibrary(tibble)\nlibrary(shiny)\nlibrary(dplyr)\n\nhelper &lt;- function(n = 250, p = .5, t = 100L, mut_to = 0, mut_from = 0,\n                   fit_AA = 1, fit_Aa = 1, fit_aa = 1) {\n  purrr::accumulate(\n    .x = vector(\"numeric\", t - 1),\n    .f = ~ {\n      # Calculate average fitness of the population\n      fit_avg = .x ^ 2 * fit_AA + 2 * .x * (1 - .x) * fit_Aa + (1 - .x) ^ 2 * fit_aa\n\n      # Calculate frequency after selection and mutation\n      p_sel = (.x * (.x * fit_AA + (1 - .x) * fit_Aa)) / fit_avg\n      p_sel_mut = (1 - mut_from ) * p_sel + (1 - p_sel) * mut_to\n\n    },\n    .init = p\n  )\n}\n\nwf_sim &lt;- function(n = 250, p = .5, t = 100L, mut_to = 0, mut_from = 0,\n                   fit_AA = 1, fit_Aa = 1, fit_aa = 1) {\n\n  # Simulate allele frequency changes using purrr::accumulate\n  allele_frequencies &lt;- purrr::accumulate(\n    .x = vector(\"numeric\", t - 1),\n    .f = ~ {\n      # Calculate average fitness of the population\n      fit_avg = .x ^ 2 * fit_AA + 2 * .x * (1 - .x) * fit_Aa + (1 - .x) ^ 2 * fit_aa\n\n      # Calculate frequency after selection and mutation\n      p_sel = (.x * (.x * fit_AA + (1 - .x) * fit_Aa)) / fit_avg\n      p_sel_mut = (1 - mut_from ) * p_sel + (1 - p_sel) * mut_to\n\n      # Generate next generation allele frequency\n      rbinom(1, 2 * n, p_sel_mut) / (2 * n)\n    },\n    .init = p\n  )\n\n  return(allele_frequencies)\n}\n\nwf_plot &lt;- function(..., num_sims = 100L, show_hist = FALSE) {\n\n  if(num_sims &lt; 1) stop(\"Invalid value of 'num_sims'\")\n\n  plot_df &lt;- reframe(\n    group_by(\n      tibble(sim = 1:num_sims), sim),\n    p = wf_sim(...), t = seq_along(p)\n  )\n\n  a &lt;- seq_along(helper(...))\n  b &lt;- helper(...)\n\n  p1 &lt;- ggplot2::ggplot(plot_df, ggplot2::aes(x = t, y = p, group = sim)) +\n    ggplot2::geom_line(linewidth = .8, alpha = .5) +\n    geom_line(\n      data = tibble(a = a, b = b), aes(x = a, y = b, group = NULL),\n      linewidth = 1, color = \"orange\"\n    ) +\n    ggplot2::scale_y_continuous(labels = scales::percent, limits = c(0, 1)) +\n    ggplot2::labs(\n      title = \"Wright-Fisher simulation of genetic drift\",\n      subtitle = \"Allele freq. (A)\",\n      x = \"Generation\", y = \"Allele freq.\"\n    )\n\n  if(show_hist) {\n  p2 &lt;- ggplot2::ggplot(\n    data = dplyr::slice(dplyr::group_by(plot_df, sim), dplyr::n()),\n    aes(p)) +\n    ggplot2::geom_histogram(color = \"white\", binwidth = .025, boundary = 0) +\n    ggplot2::scale_x_continuous(limits = c(0, 1), oob = scales::squish) +\n    ggplot2::coord_flip() +\n    ggplot2::theme(axis.title.y = ggplot2::element_blank()) +\n    ggplot2::labs(\n      subtitle = \"Freq(A) distribution\",\n      y = \"Count\"\n    ) +\n    ggplot2::theme(\n      axis.text.y = ggplot2::element_blank(),\n      panel.grid.minor.x = ggplot2::element_blank()\n    )\n\n    return((p1 + p2) + patchwork::plot_layout(widths = c(.8, .2)))\n  }\n\n  p1\n\n}\n\nui &lt;- bslib::page_sidebar(\n    title = \"Simulate Genetic Drift\",\n    sidebar = bslib::sidebar(\n      shiny::sliderInput(\"p\", label = \"Initial allele freq. (p)\", min = 0, max = 1, value = .5, ticks = FALSE),\n      shiny::sliderInput(\"n\", label = \"Population size (n)\", min = 1, max = 500, value = 250, ticks = FALSE),\n      shiny::sliderInput(\"t\", label = \"Number of generations\", min = 1, max = 200, value = 100, ticks = FALSE),\n      shiny::sliderInput(\"mut_to\", label = \"Mutation rate (a -&gt; A)\", min = 0, max = 1, value = 0, ticks = FALSE),\n      shiny::sliderInput(\"mut_from\", label = \"Mutation rate (A -&gt; a)\", min = 0, max = 1, value = 0, ticks = FALSE),\n      shiny::div(\n        style = \"display: flex; flex-direction: row;\",\n        shiny::numericInput(\"fit_AA\", \"Fit AA:\", value = 1, step = .1),\n        shiny::numericInput(\"fit_Aa\", \"Fit Aa:\", value = 1, step = .1),\n        shiny::numericInput(\"fit_aa\", \"Fit aa:\", value = 1, step = .1)\n      ),\n      shiny::numericInput(\"num_sims\", label = \"Number of simulations\", value = 100, min = 1),\n      shiny::radioButtons(\"show_hist\", label = \"Histogram\", choices = c(\"Show\", \"Hide\"), selected = \"Hide\"),\n      shiny::actionButton(\"reset\", label = \"Reset\")\n    ),\n    bslib::card(shiny::plotOutput(\"simplot\"), width = \"80%\")\n)\n\nserver &lt;- function(input, output, session) {\n  \n  input_values &lt;- shiny::reactiveValues(\n    p = 0.5,\n    n = 250,\n    t = 100,\n    mut_from = 0,\n    mut_to = 0,\n    fit_AA = 1,\n    fit_Aa = 1,\n    fit_aa = 1,\n    num_sims = 100,\n    show_hist = \"Hide\"\n  )\n  \n  shiny::observe({\n    input_values$p &lt;- input$p\n    input_values$n &lt;- input$n\n    input_values$t &lt;- input$t\n    input_values$mut_from &lt;- input$mut_from\n    input_values$mut_to &lt;- input$mut_to\n    input_values$fit_AA &lt;- input$fit_AA\n    input_values$fit_Aa &lt;- input$fit_Aa\n    input_values$fit_aa &lt;- input$fit_aa\n    input_values$num_sims &lt;- input$num_sims\n    input_values$show_hist &lt;- input$show_hist\n  })\n  \n  output$simplot &lt;- shiny::renderPlot({\n    wf_plot(\n      n = input_values$n,\n      p = input_values$p,\n      t = input_values$t,\n      mut_from = input_values$mut_from,\n      mut_to = input_values$mut_to,\n      fit_AA = input_values$fit_AA,\n      fit_Aa = input_values$fit_Aa,\n      fit_aa = input_values$fit_aa,\n      num_sims = input_values$num_sims,\n      show_hist = input_values$show_hist == \"Show\"\n    )\n  })\n  \n  shiny::observeEvent(input$reset, {\n    # Reset input_values to their default values\n    input_values$p &lt;- 0.5\n    input_values$n &lt;- 250\n    input_values$t &lt;- 100\n    input_values$mut_from &lt;- 0\n    input_values$mut_to &lt;- 0\n    input_values$fit_AA &lt;- 1\n    input_values$fit_Aa &lt;- 1\n    input_values$fit_aa &lt;- 1\n  })\n  \n  shiny::observeEvent(input$reset, {\n    # Reset all input values to their default values\n    shiny::updateSliderInput(session, \"p\", value = 0.5)\n    shiny::updateSliderInput(session, \"n\", value = 250)\n    shiny::updateSliderInput(session, \"t\", value = 100)\n    shiny::updateSliderInput(session, \"mut_from\", value = 0)\n    shiny::updateSliderInput(session, \"mut_to\", value = 0)\n    shiny::updateNumericInput(session, \"fit_AA\", value = 1)\n    shiny::updateNumericInput(session, \"fit_Aa\", value = 1)\n    shiny::updateNumericInput(session, \"fit_aa\", value = 1)\n  })\n  \n}\nshiny::shinyApp(ui, server)\n\n\n(I’m not 100% there yet - the histograms break the app, but I am on it!)"
  },
  {
    "objectID": "blog/2025-01-03-Wright-Fisher Simulation in R/wright-fisher.html#visualising-drift",
    "href": "blog/2025-01-03-Wright-Fisher Simulation in R/wright-fisher.html#visualising-drift",
    "title": "Wright-Fisher simulations in R",
    "section": "Visualising drift",
    "text": "Visualising drift\nThe following code shows my first attempt at implementing the process. This approach is pretty inefficient, and I’ll get into why a bit later in the post:\n\nwf_sim &lt;- function(p = .5, n = 50, t = 50) {\n  freqs &lt;- c(p)\n  for(i in 2:t) {\n    freqs &lt;- c(freqs, rbinom(1, size = 2*n, prob = freqs[i - 1]) / (2*n))\n  }\n  freqs\n}\n\nImagine a population of 50 animals, where you are able to measure the frequency of an allele A, once every generation. The frequency turns out to be 50% at the first generation, but for every generation that changes a little bit:\n\nlibrary(tidyverse)\n\nenframe(wf_sim(), name = \"t\", value = \"p\") %&gt;% \n  ggplot(aes(x = t, y = p)) +\n  geom_line() +\n  scale_y_continuous(labels = scales::percent, limits = c(0,1))\n\n\n\n\n\n\n\n\nNow imagine simulating this process 100 times. Even as every simulation started with the same allele frequency, every trajectory will look different. Some simulations will even have fixed or lost the allele, purely due to chance.\nLet’s try to illustrate that. This function draws the allele trajectories for every simulation, along with a histogram of the distribution of allele frequencies at the final generation. I use patchwork to stitch my plots together:\n\nlibrary(patchwork)\n\ndraw_sims &lt;- function(sims = 100, sim_function = wf_sim, ...) {\n  \n  dots &lt;- list(...)\n  \n  df &lt;- tibble(sim = seq_along(1:sims)) %&gt;% \n    group_by(sim) %&gt;% \n    reframe(\n      p = sim_function(...), t = seq_along(p)\n    ) %&gt;% \n    ungroup()\n  \n  p1 &lt;- df %&gt;% \n    ggplot(aes(x = t, y = p, group = sim)) +\n    geom_line(alpha = .25) +\n    scale_y_continuous(labels = scales::percent, limits = c(0,1)) +\n    labs(title = paste(\n      names(dots), unlist(dots), sep = \" = \", collapse = \", \")\n    )\n  \n  p2 &lt;- df %&gt;% \n    filter(t == max(t)) %&gt;% \n    ggplot(aes(y = p)) +\n    geom_histogram(bins = 20, color = \"white\") +\n    scale_y_continuous(\n      labels = scales::percent, \n      oob = scales::oob_keep, \n      limits = c(0,1)\n    ) +\n  #  coord_flip() +\n    theme(axis.text = element_blank(), axis.title = element_blank())\n  \n  p1 + p2 + plot_layout(design = \"AAAAB\", axes = 'collect')\n}\n\ndraw_sims() \n\n\n\n\n\n\n\n\nThis trajectory is dependent on population size. In smaller populations, the trajectories will be all over the place, and the eventual loss or fixation of an allele will be much more likely. The opposite is true for larger populations, and it’s going to take a lot longer for the allele to take over or disappear completely.\n\ndraw_sims(n = 10) / draw_sims(n = 500) \n\n\n\n\n\n\n\n\nIf you’re new to R programming, you might notice the use of ... ellipses in the draw_sims function. This is one of the ways R is so outrageous for programmers coming from other languages. This allows me to pass additional arguments to wf_sim() with less hard-coding. It’s kind of a rabbit hole if I elaborate, so I’m just going to gloss over that for now.\nAnother thing I like about the function is the fact that I can pass another function as an argument. It’s one of the hallmarks of functional programming, and it’s super easy to implement this style of programming in R. I do this because I plan on experimenting with a few different ways to implement wf_sim(), and it saves me the hassle of writing a draw function for each one."
  },
  {
    "objectID": "blog/2025-01-03-Wright-Fisher Simulation in R/wright-fisher.html#must-go-faster",
    "href": "blog/2025-01-03-Wright-Fisher Simulation in R/wright-fisher.html#must-go-faster",
    "title": "Wright-Fisher simulations in R",
    "section": "Must go faster",
    "text": "Must go faster\nIf you play around with wf_sim() as it’s written right now, you’ll notice that it’s slow, especiqally as t increases. This is because this part of the function is quite expensive:\n\nwf_sim &lt;- function(p = .5, n = 50, t = 50) {\n  freqs &lt;- c(p)\n  for(i in 2:t) {\n    freqs &lt;- c(freqs, rbinom(1, size = 2*n, prob = freqs[i - 1]) / (2*n))\n  }\n  freqs\n}\n\nIn each iteration of the loop, R creates a new vector to handle the additional value being appended. This new vector has to copy all of the values from the previous step in the loop, and this repeats when you get to the next step.\n\nPre-allocating vectors\nWhat you want to do instead is pre-allocate a vector with the full length, before you start looping. The loop should then update a specific index at each iteration. This removes the need to copy all the values every time (or at least that’s what I think is going on).\n\nwf_sim_vectorized &lt;- function(p = .5, n = 50, t = 50) {\n  freqs &lt;- vector(mode = \"numeric\", length = t)\n  freqs[1] &lt;- p\n  for(i in 2:t) {\n    freqs[i] &lt;- rbinom(1, size = 2*n, prob = freqs[i - 1]) / (2*n)\n  }\n  freqs\n}\n\nLet’s test if this approach is faster, using bech::mark:\n\nbench::mark(\n  wf_sim(t = 5000), \n  wf_sim_vectorized(t = 5000), \n  check = FALSE\n)\n\n# A tibble: 2 × 6\n  expression                       min   median `itr/sec` mem_alloc `gc/sec`\n  &lt;bch:expr&gt;                  &lt;bch:tm&gt; &lt;bch:tm&gt;     &lt;dbl&gt; &lt;bch:byt&gt;    &lt;dbl&gt;\n1 wf_sim(t = 5000)             28.57ms  31.43ms      31.2   107.8MB     85.7\n2 wf_sim_vectorized(t = 5000)   4.56ms   4.98ms     157.     12.2MB     43.6\n\n\nThat looks about right. My hunch is that the time it takes for the first approach to run increases by \\(O(t^2)\\) as the number of generations increases, while the vectorized function should run in linear time \\(O(t)\\).\nThe way I usually test this is to visualise it by graphs like these:\n\ntibble(t = c(50, 100, 500, 1000, 2000, 3000, 4000, 5000)) %&gt;% \n  mutate(benchmarks = map(t, ~{\n    bench::mark(\n      naive = wf_sim(t = .x),\n      vectorized = wf_sim_vectorized(t = .x),\n      check = FALSE\n    )\n  })) %&gt;% \n  unnest(benchmarks) %&gt;% \n  ggplot(aes(x = t, y = median / t, color = as.character(expression))) +\n  geom_line() +\n  geom_point() +\n  labs(color = NULL)\n\n\n\n\n\n\n\n\nNote that the y axis is time to compute divided by \\(t\\). If the function grows in linear time with \\(t\\), we expect a flat horizontal line, while a function that grows quadratically will have a linear slope like the one shown here.\n\n\nFunctional programming\nExamples like this is part of the reason why loops get such a bad rap in R. Some very common feedback I got when I was starting out R coding, was that I needed to iterate using the apply family of functions instead, or the map functions of purrr.\nLet’s try to write the same function using a function from purrr. Because I’m building a vector that repeatedly uses the result of a previous index, it calls for a function named accumulate:\n\nwf_sim_tidy &lt;- function(p = .5, n = 50, t = 50) {\n  purrr::accumulate(\n    .x = vector(mode = \"numeric\", length = t),\n    .f = ~ rbinom(1, 2 * n, .x)/(2 * n), \n    .init = p\n  )\n}\n\nThe main advantage of writing code like this is the clearer syntax; not an increase in performance. This is another example of functional programming, and is a bit less verbose than declaring vectors and writing loops.\nI used to think that functions like these were inherently faster than loops too, but if you actually compare the functions, you’ll see that there isn’t much to gain in terms of performance compared with our vectorized function. In fact, there’s going to be a bit of overhang to accumulate, so this version is a bit slower:\n\nbench::mark(\n  wf_sim(t = 5000),\n  wf_sim_vectorized(t = 5000), \n  wf_sim_tidy(t = 5000),\n  check = FALSE\n)\n\n# A tibble: 3 × 6\n  expression                       min   median `itr/sec` mem_alloc `gc/sec`\n  &lt;bch:expr&gt;                  &lt;bch:tm&gt; &lt;bch:tm&gt;     &lt;dbl&gt; &lt;bch:byt&gt;    &lt;dbl&gt;\n1 wf_sim(t = 5000)             30.22ms  32.52ms      27.4   107.8MB    103. \n2 wf_sim_vectorized(t = 5000)   4.59ms   4.83ms     173.     12.2MB     43.7\n3 wf_sim_tidy(t = 5000)         9.38ms  10.23ms      89.7    12.4MB     27.9\n\n\nThe lesson here is that loops are fine. There are some benefits to the syntax in accumulate, but they come from the code being more legible and easier to maintain. These are completely valid reasons to prefer this implementation, but if you’re more worried about performance, you might as well stick with the humble loop."
  },
  {
    "objectID": "blog/2025-01-03-Wright-Fisher Simulation in R/wright-fisher.html#understanding-wright-fisher",
    "href": "blog/2025-01-03-Wright-Fisher Simulation in R/wright-fisher.html#understanding-wright-fisher",
    "title": "Wright-Fisher simulations in R",
    "section": "Understanding Wright-Fisher",
    "text": "Understanding Wright-Fisher\nThe reason I’m writing this code is to gain a better understanding of the factors contributing to genetic drift. That means looking at the distribution of allele frequencies at the end of simulation under varying conditions, namely:\n\nPopulation size\nInitial allele frequency\nPresence of mutation rates\nPresence of natural selection\n\n\nPopulation size\nAt this point we’ve established that initial allele frequency and population size is important to our simulations. To really hammer that idea home, let’s make a high level visualization, that shows that in one big plot.\nLet’s try to look at a few different pairings of initial frequency and population size. I’m choosing 3 values of p and 3 values of n, with the intent to show the simulation results for each possible pairing. I use crossing() to make those pairs:\n\ncrossing(p_init = c(.1, .5, .9), n = c(5, 50, 500))\n\n# A tibble: 9 × 2\n  p_init     n\n   &lt;dbl&gt; &lt;dbl&gt;\n1    0.1     5\n2    0.1    50\n3    0.1   500\n4    0.5     5\n5    0.5    50\n6    0.5   500\n7    0.9     5\n8    0.9    50\n9    0.9   500\n\n\nNow let’s make 100 simulations for each of these pairs:\n\nwf_sims &lt;- crossing(sim = 1:100, p_init = c(.1, .5, .9), n = c(5, 50, 500)) %&gt;% \n  group_by(sim, p_init, n) %&gt;% \n  reframe(\n    p = wf_sim_tidy(p = p_init, n = n),\n    t = seq_along(p)\n  ) %&gt;% \n  ungroup()\n\nwf_sims\n\n# A tibble: 45,900 × 5\n     sim p_init     n     p     t\n   &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n 1     1    0.1     5   0.1     1\n 2     1    0.1     5   0.1     2\n 3     1    0.1     5   0       3\n 4     1    0.1     5   0       4\n 5     1    0.1     5   0       5\n 6     1    0.1     5   0       6\n 7     1    0.1     5   0       7\n 8     1    0.1     5   0       8\n 9     1    0.1     5   0       9\n10     1    0.1     5   0      10\n# ℹ 45,890 more rows\n\n\nWith a data frame like this, we can show the varying values of n and p using a faceted ggplot:\n\nwf_sims %&gt;% \n  ggplot(aes(x = t, y = p, group = sim)) +\n  geom_line(alpha = .2) +\n  facet_grid(paste(\"p_init = \", p_init) ~ paste(\"n = \", n)) +\n  scale_y_continuous(labels = scales::percent) \n\n\n\n\n\n\n\n\nIt’s a bit overwhelming to look at all of this, but if you spend some time thinking about the factors for each facet, I hope to help you build some intuition of the trajectories for each condition.\n\nTop left plot shows a tiny population, where the initial frequency is very low. As the frequency fluctuates so much with the small population size, many of the simulations end in fixation of the allele, even with low intial frequency.\nBottom right plot shows a large population with a high initial frequency. Here the trajectories are more stable, and very few simulation (if any) end in loss of the allele.\n\nThe frequencies at the end of the simulations get muddled out, though. Let’s look at the resulting distributions:\n\nwf_sims %&gt;% \n  filter(t == max(t)) %&gt;% \n  ggplot(aes(x = p)) +\n  geom_histogram(color = \"white\", bins = 20) +\n  facet_grid(paste(\"p_init = \", p_init) ~ paste(\"n = \", n)) +\n  scale_x_continuous(labels = scales::percent) \n\n\n\n\n\n\n\n\nThat gives me the distributions, but the plot I have in my head shows the combined line graphs, with the resulting distributions that came with the draw_sims function, as I found that helped me understand what was going on. It’s hard to show that with regular ggplot facets, so I’m resorting to draw 9 plots using draw_sims, and gathering them in a list:\n\nwf_plots &lt;- crossing(p_init = c(.1, .5, .9), n = c(5, 50, 500)) %&gt;% \n  rowwise() %&gt;% \n  mutate(plots = list(\n    draw_sims(sim_function = wf_sim_tidy, p = p_init, n = n)\n    )\n  )  %&gt;% \n  pull(plots) \n\nWhen I have this list of plots, I can wrap them up using the wrap_plots function of patchwork:\n\nwrap_plots(wf_plots) & \n  theme_grey(base_size = 8) &\n  theme(\n    axis.text = element_blank(), \n    axis.title.x = element_blank()\n  )\n\n\n\n\n\n\n\n\nThis has roughly the same layout as the previous faceted graphs, except I get to marvel at the trajectories and distributions all at once. There’s a lot of high-level things going on right now, but I think it’s all in service of understanding the nature of the simulations, once you dwell a bit on each plot.\n\n\nMutation\nAside from genetic drift, the frequencies can also be impacted by the introduction of new alleles that happen by mutation. In a two-allele system, we can model this with 2 rates:\n\nmut_from: Probability that that the allele A changes from its current state into another allele a.\nmut_to: The probability that the gene mutates from allele a into A.\n\nThis is relatively simple to include in the function:\n\nwf_sim_mutation &lt;- function(p = .5, n = 50, t = 50, mut_from = 0, mut_to = 0){\n  freqs &lt;- vector(mode = \"numeric\", length = t)\n  freqs[1] &lt;- p\n  \n  for(i in 2:t) {\n    p_mut &lt;- (1 - mut_from) * freqs[i - 1] + mut_to * (1 - freqs[i - 1])\n    freqs[i] &lt;- rbinom(1, 2 * n, p_mut) / (2 * n)\n  }\n  freqs\n}\n\nSay you model a population where a specific allele isn’t present at all. Because the allele is lost from the beginning, it will stay lost after 50 generations. But if you introduce a chance every generation, of say 10%, that the allele will appear by random mutation, that might be enough for the allele to fix in population for pretty much all simulations:\n\ndraw_sims(p = 0) | \ndraw_sims(sim_function = wf_sim_mutation, p = 0, mut_to = .10)\n\n\n\n\n\n\n\n\nAnother thing that fascinates me is the fact that a two-allele system like this has a mutation equilibrium, where the rates of mut_to and mut_from are equal. This leads to stable allele frequencies over time, regardless of initiall allele frequency, which can be predicted with this formula:\n\\[p_{\\text{eq}} = \\frac{\\mu_{\\text{ to}}}{\\mu_{\\text{ from}} + \\mu_{\\text{ to}}}\\]\n\ndraw_sims(sim_function = wf_sim_mutation, p = 0, mut_from = .1, mut_to = .2) & \n  geom_abline(intercept = (.2) / (.1 + .2), slope = 0, color = \"orange\")\n\n\n\n\n\n\n\n\nThat equilibrium is reached, even if the allele is fixed from the start instead:\n\ndraw_sims(sim_function = wf_sim_mutation, p = 1, mut_from = .1, mut_to = .2) & \n  geom_abline(intercept = (.2) / (.1 + .2), slope = 0, color = \"orange\")\n\n\n\n\n\n\n\n\n\n\nSelection\nAt this point, I might as well mention selection. Selection introduces a bias in the allele frequencies being drawn at each generation, by favoring certain alleles, or genotypes. In our diploid two-allele system, where alleles are called \\(A\\) and \\(a\\), the relative fitness of each genotype can be denoted as \\(w_{AA}\\), \\(w{Aa}\\), and \\(w_{aa}\\). The probability of sampling allele \\(A\\) every generation will be adjusted as follows:\n\\[p_{\\text{sel}} = \\frac{p^2 \\cdot w_{AA} + p \\cdot q \\cdot w_{Aa}}{p^2 \\cdot w_{AA} + 2 \\cdot p \\cdot q \\cdot w_{Aa} + q^2 \\cdot w_{aa}}\\]\nHere: - p is the frequency of allele A, - q = 1 - p, which is the frequency of allele a, - \\(w_{AA}\\), \\(w_{Aa}\\), and \\(w_{aa}\\) are the fitnesses of the \\(AA\\), \\(Aa\\), and \\(aa\\) genotypes, respectively.\n\nwf_sim_selection &lt;- function(p = .5, n = 50, t = 50, fit_AA = 1, fit_Aa = 1, fit_aa = 1) {\n\n  freqs &lt;- vector(mode = \"numeric\", length = t)\n  freqs[1] &lt;- p\n\n  for(i in 2:t) {\n    # Calculate average fitness of the population\n    fit_avg &lt;-\n      freqs[i - 1] ^ 2 * fit_AA + \n      (1 - freqs[i - 1]) ^ 2 * fit_aa +\n      2 * freqs[i - 1] * (1 - freqs[i - 1]) * fit_Aa\n\n    p_sel &lt;- \n      (freqs[i - 1] * (freqs[i - 1] * fit_AA + (1 - freqs[i - 1]) * fit_Aa)) / \n      (fit_avg)\n        \n    freqs[i] &lt;- rbinom(1, 2 * n, p_sel) / (2 * n)\n  }\n  \n  freqs\n}\n\nSay that the aa genotype only has a relative fitness at half of the AA and Aa genotypes. Even if the a allele is the most prominent one at the start, most simulations will end in the A allele being fixed in these conditions.\n\ndraw_sims(sim_function = wf_sim_selection, p = 0.01, fit_aa = .5)\n\n\n\n\n\n\n\n\nStill, some of simulations end in the \\(A\\) allele being lost, as the initial allele frequency is very low. At this point, there’s a tug-of-war going on, where genetic drift wants to delete the allele entirely, while selection tries to fix the allele completely."
  },
  {
    "objectID": "blog/2025-01-03-Wright-Fisher Simulation in R/wright-fisher.html#lessons-learned",
    "href": "blog/2025-01-03-Wright-Fisher Simulation in R/wright-fisher.html#lessons-learned",
    "title": "Wright-Fisher simulations in R",
    "section": "Lessons learned",
    "text": "Lessons learned\nWright-Fisher is a powerful tool to model and understand how various processes affect the genetic composition of populations. I hope this post helped you understand how population size, mutation, and selection interact with genetic drift to shape allele frequencies in a population.\n\nPopulation size matters. Small populations show faster fixation or loss of alleles, as random genetic drift is much stronger here.\nMutation and selection counteract drift.\nImplementation matters for efficiency. Some of the simulation functions implemented here produced the exact same output, but had vastly different run times.\n\nI think the most powerful part of this whole thing is the inclusion of the shinylive app. Tinkering with tools like this is probably the most effective way of gaining intuition for these kinds of models - that along with effective visualization."
  },
  {
    "objectID": "projects/index.html",
    "href": "projects/index.html",
    "title": "Projects",
    "section": "",
    "text": "Predicting House Prices with Machine Learning\n\n\n\nPython\n\n\nMachine Learning\n\n\nData Cleaning\n\n\n\nThis project involves using machine learning algorithms to predict house prices based on various features such as location, size, and amenities. It includes data cleaning, feature engineering, and model selection.\n\n\n\nJan 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCustomer Segmentation Using Clustering Techniques\n\n\n\nR\n\n\nMachine Learning\n\n\nClustering\n\n\nStatistical Modelling\n\n\n\nThis project focuses on segmenting customers into different groups based on their purchasing behavior and demographics. It uses clustering algorithms like K-means and hierarchical clustering to identify distinct customer segments.\n\n\n\nApr 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVisualizing Global CO2 Emissions\n\n\n\nR\n\n\nData Visualization\n\n\nEnvironmental Science\n\n\n\nThis project involves creating visualizations to show trends in global CO2 emissions over time. It includes data extraction from public databases, data cleaning, and using visualization libraries to create interactive charts and graphs.\n\n\n\nJul 1, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Emil Nikki Malta",
    "section": "",
    "text": "I’m Emil. I work with data (mostly healthcare and demographics), turning tangled data into tools and visuals people can actually use.\nI like creative problem-solving, data storytelling, and learning new things. Outside of work, I’m either chasing my kids, or exploring new ideas and tools."
  },
  {
    "objectID": "index.html#hi",
    "href": "index.html#hi",
    "title": "Emil Nikki Malta",
    "section": "",
    "text": "I’m Emil. I work with data (mostly healthcare and demographics), turning tangled data into tools and visuals people can actually use.\nI like creative problem-solving, data storytelling, and learning new things. Outside of work, I’m either chasing my kids, or exploring new ideas and tools."
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Emil Nikki Malta",
    "section": "Experience",
    "text": "Experience\nData Consultant\nRegion Midtjylland (Aarhus, 2021 - Present)\n\nI develop high-quality analysis tools and pipelines for healthcare procurement, contract management, and logistics.\nCollaboration with interdisciplinary teams. Focus on environmental impact of procurement and logistics.\n\nStatistics Officer (AC)\nStatistics Greenland (Nuuk, 2018 - 2021)\n\nStatistical programming and maintenance of official national registers."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Emil Nikki Malta",
    "section": "Education",
    "text": "Education\nM.Sc. Bioinformatics\nAarhus University (2016 - 2018)\n\nStatistical modeling and data analysis.\nFocus on application in forensics - e.g. statistical mass spectrometry analysis of fingerprint residue, using regression and classification trees.\n\nB.Sc. Molecular Biology\nAarhus University (2013 - 2016)\n\nMinor in Bioinformatics. Focus on genetic epidemiology."
  },
  {
    "objectID": "blog/2025-01-01-Nuuk Population Dynamics/visualising-nuuk.html",
    "href": "blog/2025-01-01-Nuuk Population Dynamics/visualising-nuuk.html",
    "title": "Population Dynamics of Nuuk",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(osmdata)\n\nnuuk_roads &lt;- opq(\"Nuuk, Greenland\") %&gt;% \n  add_osm_feature(\"highway\") %&gt;% \n  osmdata_sf() %&gt;% \n  pluck(\"osm_lines\")\n\nnuuk_buildings &lt;- opq(\"Nuuk, Greenland\") %&gt;% \n  add_osm_feature(\"building\") %&gt;% \n  osmdata_sf() %&gt;% \n  pluck(\"osm_polygons\")\n\nggplot() +\n  geom_sf(data = nuuk_roads, linewidth = .5) +\n  geom_sf(data = nuuk_buildings)  +\n  coord_sf(xlim = c(-51.748, -51.65), ylim = c(64.157, 64.203)) +\n  theme_void()\n\n\n\n\n\n\n\n\n\nI lived in Nuuk, the Capital city of Greenland, for 3 years. Per the latest census, it has a total population of 19,872 people. I know that sounds tiny, considering that it’s an actual capital of an actual country, but it never felt small while I was there.\nThe city had just expanded, with many people (families especially), moving into the eastern part of town called Qinngorput.\nThere are now 4 distinct parts of town, called city districts: Downtown Nuuk (just called Nuuk), Quassussuup Tungaa, Nuussuaq and Qinngorput. Every district has its own vibe. Some have more immigrants and students, and some are full of families with children.\nIn this post, I’ll walk you through how I would go about analyzing the population structure of Nuuk, using R and the Tidyverse."
  },
  {
    "objectID": "blog/2025-01-01-Nuuk Population Dynamics/visualising-nuuk.html#the-city",
    "href": "blog/2025-01-01-Nuuk Population Dynamics/visualising-nuuk.html#the-city",
    "title": "Population Dynamics of Nuuk",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(osmdata)\n\nnuuk_roads &lt;- opq(\"Nuuk, Greenland\") %&gt;% \n  add_osm_feature(\"highway\") %&gt;% \n  osmdata_sf() %&gt;% \n  pluck(\"osm_lines\")\n\nnuuk_buildings &lt;- opq(\"Nuuk, Greenland\") %&gt;% \n  add_osm_feature(\"building\") %&gt;% \n  osmdata_sf() %&gt;% \n  pluck(\"osm_polygons\")\n\nggplot() +\n  geom_sf(data = nuuk_roads, linewidth = .5) +\n  geom_sf(data = nuuk_buildings)  +\n  coord_sf(xlim = c(-51.748, -51.65), ylim = c(64.157, 64.203)) +\n  theme_void()\n\n\n\n\n\n\n\n\n\nI lived in Nuuk, the Capital city of Greenland, for 3 years. Per the latest census, it has a total population of 19,872 people. I know that sounds tiny, considering that it’s an actual capital of an actual country, but it never felt small while I was there.\nThe city had just expanded, with many people (families especially), moving into the eastern part of town called Qinngorput.\nThere are now 4 distinct parts of town, called city districts: Downtown Nuuk (just called Nuuk), Quassussuup Tungaa, Nuussuaq and Qinngorput. Every district has its own vibe. Some have more immigrants and students, and some are full of families with children.\nIn this post, I’ll walk you through how I would go about analyzing the population structure of Nuuk, using R and the Tidyverse."
  },
  {
    "objectID": "blog/2025-01-01-Nuuk Population Dynamics/visualising-nuuk.html#data-import",
    "href": "blog/2025-01-01-Nuuk Population Dynamics/visualising-nuuk.html#data-import",
    "title": "Population Dynamics of Nuuk",
    "section": "Data import",
    "text": "Data import\nStatistics Greenland maintains a census table on the population of Nuuk, updated once a year. It’s available through the Statbank here. While I could go ahead and download the data from their site, it’s much easier to query the API from R instead.\nI wrote an API wrapper for work few years ago, while I still worked full time at Stats Greenland. This was written to speed up my workflow, when working with Statbank data in R, and was mostly for internal use. We ended up publishing it on our Github.\nKnowing that the Table ID for the data I’m interested in is \"BEESTNUK\", I can fetch the data like this:\n\nlibrary(statgl)\n\nstatgl_fetch(\"BEESTNUK\")\n\n# A tibble: 31 × 2\n   time  value\n   &lt;chr&gt; &lt;int&gt;\n 1 1994  12483\n 2 1995  12723\n 3 1996  12882\n 4 1997  12909\n 5 1998  13024\n 6 1999  13169\n 7 2000  13445\n 8 2001  13649\n 9 2002  13884\n10 2003  13884\n# ℹ 21 more rows\n\n\nBy default, it’s going to give me all values in the mandatory variables, which in this case is time. I can explore what options I have for querying this table by calling statgl_meta(\"BEESTNUK\"), and once I know what I need, I can make a query that looks like this:\n\nnuk_raw &lt;- statgl_fetch(\n  \"BEESTNUK\", age = 0:99, citydistrict = c(1:4, 9),\n  `place of birth` = c(\"N\", \"S\"), gender = c(\"M\", \"K\")\n)\n\nnuk_raw\n\n# A tibble: 62,000 × 6\n   age   citydistrict `place of birth` gender time  value\n   &lt;chr&gt; &lt;chr&gt;        &lt;chr&gt;            &lt;chr&gt;  &lt;chr&gt; &lt;int&gt;\n 1 0     Nuuk         Greenland        Men    1994     63\n 2 0     Nuuk         Greenland        Men    1995     75\n 3 0     Nuuk         Greenland        Men    1996     71\n 4 0     Nuuk         Greenland        Men    1997     57\n 5 0     Nuuk         Greenland        Men    1998     78\n 6 0     Nuuk         Greenland        Men    1999     65\n 7 0     Nuuk         Greenland        Men    2000     50\n 8 0     Nuuk         Greenland        Men    2001     47\n 9 0     Nuuk         Greenland        Men    2002     50\n10 0     Nuuk         Greenland        Men    2003     54\n# ℹ 61,990 more rows\n\n\nThis is basically a count table. Reading the first row tells me that on Jan. 1st 1994, there were 63 boys aged 0, who were born in Greenland, and lived in the Nuuk city district. That number was 75 the year after and so on."
  },
  {
    "objectID": "blog/2025-01-01-Nuuk Population Dynamics/visualising-nuuk.html#tidy",
    "href": "blog/2025-01-01-Nuuk Population Dynamics/visualising-nuuk.html#tidy",
    "title": "Population Dynamics of Nuuk",
    "section": "Tidy",
    "text": "Tidy\nWhen tidying data, I first want to make sure that every column is a variable. That seems to be the case in this data, so my next instinct is to make sure that every row is an observation. In other words: I want to make sure that every row in this dataset is a person.\nThere is a cool function in the tidyr package called uncount, which repeats rows in a dataset according to a weighting variable. This means that I can turn the 63 boys I talked about earlier, into 63 rows in the dataset:\n\nlibrary(tidyverse)\n\nnuk_raw %&gt;% uncount(value)\n\n# A tibble: 484,724 × 5\n   age   citydistrict `place of birth` gender time \n   &lt;chr&gt; &lt;chr&gt;        &lt;chr&gt;            &lt;chr&gt;  &lt;chr&gt;\n 1 0     Nuuk         Greenland        Men    1994 \n 2 0     Nuuk         Greenland        Men    1994 \n 3 0     Nuuk         Greenland        Men    1994 \n 4 0     Nuuk         Greenland        Men    1994 \n 5 0     Nuuk         Greenland        Men    1994 \n 6 0     Nuuk         Greenland        Men    1994 \n 7 0     Nuuk         Greenland        Men    1994 \n 8 0     Nuuk         Greenland        Men    1994 \n 9 0     Nuuk         Greenland        Men    1994 \n10 0     Nuuk         Greenland        Men    1994 \n# ℹ 484,714 more rows"
  },
  {
    "objectID": "blog/2025-01-01-Nuuk Population Dynamics/visualising-nuuk.html#transform",
    "href": "blog/2025-01-01-Nuuk Population Dynamics/visualising-nuuk.html#transform",
    "title": "Population Dynamics of Nuuk",
    "section": "Transform",
    "text": "Transform\nFor good measure, I’m making sure that age and time are defined as numeric variables:\n\nnuk_tidy &lt;- \n  nuk_raw %&gt;%\n  uncount(value) %&gt;% \n  mutate(age = as.numeric(age), time = as.numeric(time))\n\nI plan to dive into data from the latest census data when analyzing population structure. I have to make sure that I only look at data from the latest census when doing that:\n\nnuk_latest &lt;- nuk_tidy %&gt;% \n  filter(time == max(time))"
  },
  {
    "objectID": "blog/2025-01-01-Nuuk Population Dynamics/visualising-nuuk.html#visualize",
    "href": "blog/2025-01-01-Nuuk Population Dynamics/visualising-nuuk.html#visualize",
    "title": "Population Dynamics of Nuuk",
    "section": "Visualize",
    "text": "Visualize\nThe whole point of visualizing data is to challenge your intuition. At the beginning of an analysis, you probably have a number of preconceived notions of the patterns you will find, like I did when looking at the data for the population of Nuuk.\nWhen drawing plots, you’re not looking for images that will prove your point. Indeed, if a plot proves you right in whatever notion you had, it’s probably not worth showing. The real power of a plot is that it can fundamentally surprise you, and you should chase the surprises if you’re looking for actual insight.\n\nTime series\nLet’s look at the population growth of town over time:\n\nnuk_tidy %&gt;% \n  ggplot(aes(x = time)) +\n  geom_line(stat = \"count\")\n\n\n\n\n\n\n\n\nNot that many surprises here. Population size has been on a steady ascent for decades, though it does seem to pick up lately. I would assume that it’s because of the new city district, right? Let’s try to visualize the growth of each district:\n\nnuk_tidy %&gt;% \n  ggplot(aes(x = time, fill = citydistrict)) +\n  geom_area(stat = \"count\", color = \"white\")\n\n\n\n\n\n\n\n\nThis plot changes my take on things. It seems that the expansion in Qinngorput happens at the expense of growth in other parts of town, especially Quassussuup Tungaa. The people who were likely to move to Quassussuup, ended up moving to Qinngorput once there was space for them there.\nMy assumption is also that there are clear differences in the composition of age between the districts. My take was always that young people lived in Qinngorput and Quassussuup, while older people lived in Nuuk and Nuussuaq. This is a plot of the mean ages for each district:\n\nnuk_tidy %&gt;% \n  ggplot(aes(x = time, y = age, color = citydistrict)) +\n  geom_line(stat = \"summary\", fun = \"mean\") \n\n\n\n\n\n\n\n\nThe Unknown group consists of very few people, so the pattern here is more of a data quality issue. The most interesting pattern is that of Qinngorput. I know that there are many families with children, so I’m guessing that’s what drives the (sustained) low mean age.\nI also found another pattern when messing around with visualizing time series. I would expect there to be a 50-50 split of men and women in town, and for that to be pretty steady across time. Right?\n\nnuk_tidy %&gt;% \n  ggplot(aes(x = time, color = gender)) +\n  geom_line(stat = \"count\")\n\n\n\n\n\n\n\n\nWait, what?\n\n\nDistributions\nThe last plot taught me that there are substantially more men than women in Nuuk. I have a couple of ideas why, one of which is distribution of age. Looking at the latest census data, I can visualise the distribution like this:\n\nnuk_latest %&gt;% \n  ggplot(aes(x = age, fill = gender)) +\n  geom_histogram(binwidth = 1)\n\n\n\n\n\n\n\n\nThe two big humps in the distribution are millennials and boomers. Histograms colored in by a categorical variable like this, show the groups stacked on top of each other by default. This actually makes it hard to compare the groups, and can even give the false impression that there are twice as many men as women, across all age groups.\nA more sensible way to compare the distributions is to position one group in front of the other, rather than on top. This is done with a position = \"identity\" statement:\n\nnuk_latest %&gt;% \n  ggplot(aes(x = age, fill = gender)) +\n  geom_histogram(binwidth = 1, position = \"identity\", alpha = .6)\n\n\n\n\n\n\n\n\nThis tells me that number of men and women are about the same for milennials and younger, and there are more men than women in ages 40 and up.\nA better way of comparing the distribution would probably be to map the genders to the x-axis, the ages to the y-axis, and representing the distribution by some kind of geom. A very common example is the boxplot:\n\nnuk_latest %&gt;% \n  ggplot(aes(x = gender, y = age)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\nWhile the boxplot is super common, especially in statistical texts, I’ve come to dislike them for 2 main reasons:\n\nThe stats needed to draw them are not self-explanatory. You need to know what a median and IQR is, and how the whiskers are defined can even change between plots.\nThe rich distribution we saw earlier is completely gone.\n\nI think a better alternative is to draw a violin. While it’s not completely apparent what determines the width of the violin, it at least makes some intuitive sense. You capture more of the richness of the distributions too:\n\nnuk_latest %&gt;% \n  ggplot(aes(x = gender, y = age)) +\n  geom_violin()\n\n\n\n\n\n\n\n\nI can definitely tell that the violin representing men is wider at ages 40-50, while narrower in the same age range for women. While this is better, I still don’t have a good grasp of the size for the each group. When I’m in this situation, I would like to show the data - e.g. drawing a point for each observation. Something like:\n\nnuk_latest %&gt;% \n  ggplot(aes(x = gender, y = age)) +\n  geom_point(size = .1, position = \"jitter\")\n\n\n\n\n\n\n\n\nWhile the dense regions with millennials and boomers are apparent, I’d say a jitter like this actually gives a worse sense of the distributions. The best graph I can come up with is a compromise between a violin and a jitter, called a sina. There’s a geom function for it in a ggplot2 extension called ggforce:\n\nlibrary(ggforce)\n\nnuk_latest %&gt;% \n  ggplot(aes(x = gender, y = age, color = gender)) +\n  ggforce::geom_sina(size = .1)\n\n\n\n\n\n\n\n\n\n\nFacets\nI’m still interested in comparing different groups of the data set. A very effective way of doing that is to draw different facets in the plot, i.e. repeating the same plot for different subsets of the data. If I facet the plot according to the column called place of birth, I get this graph:\n\nnuk_latest %&gt;% \n  ggplot(aes(x = gender, y = age, color = gender)) +\n  ggforce::geom_sina(size = .1) +\n  facet_wrap(~`place of birth`)\n\n\n\n\n\n\n\n\nThis plot genuinely blew my mind, first time I drew it. It explains why there are more men than women in the city, and tells an engaging story of the differences in the population of town. There is a definite difference in the age distribution of genders, primarily in people born outside of Greenland.\nI wonder if it was always like this? I can do a quick filter on the tidy dataset, to see if it was like this in the earliest data (1994):\n\nnuk_tidy %&gt;% \n  filter(time == min(time)) %&gt;% \n  ggplot(aes(x = gender, y = age, color = gender)) +\n  ggforce::geom_sina(size = .1) +\n  facet_wrap(~`place of birth`)\n\n\n\n\n\n\n\n\nYeah, something has happened. The age distribution of women born outside Greenland is especially interesting.\nOne final thesis I have, is that the different districts have distinct age distributions. I alluded to this in the time series of mean ages I drew earlier. I can keep the facets of birthplace, and introduce another facet by calling facet_grid:\n\nnuk_latest %&gt;% \n  ggplot(aes(x = gender, y = age, color = gender)) +\n  ggforce::geom_sina(size = .1) +\n  facet_grid(`place of birth` ~ citydistrict)\n\n\n\n\n\n\n\n\nWhile this plot can be a bit overwhelming, I like how it displays every variable of the dataset. All of the information is there, and it’s easy to tell if one group differs from others in the city.\nPeople born outside Greenland explain many of the dynamics in town, especially the men aged 40 and over. Qinngorput is a definite suburb, with many kids compared to the other districts.\nOne final thing I want to change is the order in which the information is shown. Right now, all of the categorical variables are sorted alphabetically, which is pretty much arbitrary. I think a better way of displaying the data, is to sort them by the number of observations in each group. This can be done by using the fct_infreq function of forcats:\n\nnuk_latest %&gt;% \n  mutate(across(where(is.character), fct_infreq)) %&gt;% \n  ggplot(aes(x = gender, y = age, color = gender)) +\n  ggforce::geom_sina(size = .1) +\n  facet_grid(`place of birth` ~ citydistrict) \n\n\n\n\n\n\n\n\n\n\nTheme\nThis final plot shows most of the insight I was able to gather from analysis. To make sure it’s presentable, I would spend some time making it more visually appealing. This means picking good colors for the scale, a better background color, tweaking grid lines etc.\nThe statgl package comes with a color scale function, which I like.\nSome time should be spent thinking about a good title and caption, and what axis labels should be there. Something like this:\n\nnuk_latest %&gt;% \n  mutate(\n    citydistrict = word(citydistrict),\n    across(where(is.character), fct_infreq)\n  ) %&gt;% \n  ggplot(aes(x = gender, y = age, color = gender)) +\n  ggforce::geom_sina(size = .1) +\n  facet_grid(`place of birth` ~ citydistrict) +\n  scale_color_statgl() +\n  scale_y_continuous(labels = scales::unit_format(suffix = \" yrs\")) +\n  labs(\n    title = \"Where are the women of Nuuk?\",\n    subtitle = \"Immigrant dynamics drive a stark gender imbalance in Greenland's capital\",\n    caption = paste0(\"Source: bank.stat.gl/BEESTNUK (\", max(nuk_tidy$time), \")\"),\n    x = NULL, y = NULL) +\n  theme_light() +\n  theme(\n    panel.grid.major.y = element_blank(),\n    legend.position = \"none\"\n  )"
  },
  {
    "objectID": "blog/2025-01-01-Nuuk Population Dynamics/visualising-nuuk.html#some-takeaways",
    "href": "blog/2025-01-01-Nuuk Population Dynamics/visualising-nuuk.html#some-takeaways",
    "title": "Population Dynamics of Nuuk",
    "section": "Some takeaways",
    "text": "Some takeaways\n\nThere are many more men than women in Nuuk, and the men tend to be older.\nThis is in large part due to immigration.\nYoungest part of town is Qinngorput, with young parents and children being a reason why.\n\nI hope this was helpful. Small projects like this was a big part of how I got comfortable working with R and other data science tools."
  }
]